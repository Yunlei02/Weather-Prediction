{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e26759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4660981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/yunlei/Desktop/MGMT 478/Combined dataset_nonsort.csv') # change the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48ac78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION         0\n",
       "NAME            0\n",
       "LATITUDE        0\n",
       "LONGITUDE       0\n",
       "ELEVATION       0\n",
       "DATE            0\n",
       "AWND          700\n",
       "PRCP            8\n",
       "SNOW         1713\n",
       "TAVG           27\n",
       "TMAX           10\n",
       "TMIN           25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d30eb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data prepossessing\n",
    "# Convert DATE column to datetime format\n",
    "data['DATE'] = pd.to_datetime(data['DATE'])\n",
    "# Extract year and month from DATE as new features\n",
    "data['YEAR'] = data['DATE'].dt.year\n",
    "data['MONTH'] = data['DATE'].dt.month\n",
    "# Drop the 'SNOW' column\n",
    "data_cleaned = data.drop(['SNOW'], axis=1)\n",
    "# Convert non-numeric to numeric\n",
    "for column in ['LATITUDE','LONGITUDE','ELEVATION','AWND', 'TAVG', 'TMAX', 'TMIN']:\n",
    "    data_cleaned[column] = pd.to_numeric(data_cleaned[column], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d4daf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputer missing data as median of the column\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "data_cleaned[['AWND', 'TAVG', 'TMAX', 'TMIN']] = imputer.fit_transform(data_cleaned[['AWND', 'TAVG', 'TMAX', 'TMIN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "371ece19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>AWND</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00014835</td>\n",
       "      <td>LAFAYETTE PURDUE UNIVERSITY AIRPORT, IN US</td>\n",
       "      <td>40.41236</td>\n",
       "      <td>-86.94739</td>\n",
       "      <td>181.7</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.01</td>\n",
       "      <td>23.5</td>\n",
       "      <td>29.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00014835</td>\n",
       "      <td>LAFAYETTE PURDUE UNIVERSITY AIRPORT, IN US</td>\n",
       "      <td>40.41236</td>\n",
       "      <td>-86.94739</td>\n",
       "      <td>181.7</td>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.61</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32.8</td>\n",
       "      <td>19.1</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USW00014835</td>\n",
       "      <td>LAFAYETTE PURDUE UNIVERSITY AIRPORT, IN US</td>\n",
       "      <td>40.41236</td>\n",
       "      <td>-86.94739</td>\n",
       "      <td>181.7</td>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.22</td>\n",
       "      <td>44.8</td>\n",
       "      <td>55.1</td>\n",
       "      <td>34.6</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USW00014835</td>\n",
       "      <td>LAFAYETTE PURDUE UNIVERSITY AIRPORT, IN US</td>\n",
       "      <td>40.41236</td>\n",
       "      <td>-86.94739</td>\n",
       "      <td>181.7</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2.49</td>\n",
       "      <td>58.1</td>\n",
       "      <td>70.4</td>\n",
       "      <td>45.8</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00014835</td>\n",
       "      <td>LAFAYETTE PURDUE UNIVERSITY AIRPORT, IN US</td>\n",
       "      <td>40.41236</td>\n",
       "      <td>-86.94739</td>\n",
       "      <td>181.7</td>\n",
       "      <td>2010-05-01</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.55</td>\n",
       "      <td>64.7</td>\n",
       "      <td>75.2</td>\n",
       "      <td>54.2</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION                                        NAME  LATITUDE  \\\n",
       "0  USW00014835  LAFAYETTE PURDUE UNIVERSITY AIRPORT, IN US  40.41236   \n",
       "1  USW00014835  LAFAYETTE PURDUE UNIVERSITY AIRPORT, IN US  40.41236   \n",
       "2  USW00014835  LAFAYETTE PURDUE UNIVERSITY AIRPORT, IN US  40.41236   \n",
       "3  USW00014835  LAFAYETTE PURDUE UNIVERSITY AIRPORT, IN US  40.41236   \n",
       "4  USW00014835  LAFAYETTE PURDUE UNIVERSITY AIRPORT, IN US  40.41236   \n",
       "\n",
       "   LONGITUDE  ELEVATION       DATE  AWND  PRCP  TAVG  TMAX  TMIN  YEAR  MONTH  \n",
       "0  -86.94739      181.7 2010-01-01   8.5  1.01  23.5  29.5  17.5  2010      1  \n",
       "1  -86.94739      181.7 2010-02-01   7.6  0.61  26.0  32.8  19.1  2010      2  \n",
       "2  -86.94739      181.7 2010-03-01   7.2  3.22  44.8  55.1  34.6  2010      3  \n",
       "3  -86.94739      181.7 2010-04-01   8.1  2.49  58.1  70.4  45.8  2010      4  \n",
       "4  -86.94739      181.7 2010-05-01   6.7  5.55  64.7  75.2  54.2  2010      5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46a00699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION      0\n",
       "NAME         0\n",
       "LATITUDE     0\n",
       "LONGITUDE    0\n",
       "ELEVATION    0\n",
       "DATE         0\n",
       "AWND         0\n",
       "PRCP         8\n",
       "TAVG         0\n",
       "TMAX         0\n",
       "TMIN         0\n",
       "YEAR         0\n",
       "MONTH        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b695ad87",
   "metadata": {},
   "source": [
    "<font color='red'>Note: I do some basic data clean, which imputer missing data as median of the column.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "497bf6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "stations = data_cleaned[['STATION', 'NAME', 'LATITUDE', 'LONGITUDE']].drop_duplicates()\n",
    "coordinates = stations[['LATITUDE', 'LONGITUDE']]\n",
    "neighbors_model = NearestNeighbors(n_neighbors=6)\n",
    "neighbors_model.fit(coordinates)\n",
    "\n",
    "def six_nearest_weather_stations(latitude, longitude):\n",
    "    query_coordinates = np.array([[latitude, longitude]])\n",
    "    distances, indices = neighbors_model.kneighbors(query_coordinates)\n",
    "    nearest_stations_info = stations.iloc[indices[0]].copy() \n",
    "    nearest_stations_info['DISTANCE(Â°)'] = distances[0]\n",
    "\n",
    "    return nearest_stations_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e8723ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_values_for_nearest_stations_exclude(latitude, longitude, station_to_exclude):\n",
    "    nearest_stations_info = six_nearest_weather_stations(latitude, longitude)\n",
    "    nearest_station_ids = nearest_stations_info['STATION'].tolist()\n",
    "    \n",
    "    # Remove the specific station ID from the list\n",
    "    if station_to_exclude in nearest_station_ids:\n",
    "        nearest_station_ids.remove(station_to_exclude)\n",
    "    \n",
    "    filtered_data = data_cleaned[data_cleaned['STATION'].isin(nearest_station_ids)]\n",
    "    average_values = filtered_data.groupby(['YEAR', 'MONTH'])[['AWND', 'PRCP', 'TAVG', 'TMAX', 'TMIN']].mean().reset_index()\n",
    "    average_values.rename(columns={\n",
    "        'AWND': 'AWND_avg',\n",
    "        'PRCP': 'PRCP_avg',\n",
    "        'TAVG': 'TAVG_avg',\n",
    "        'TMAX': 'TMAX_avg',\n",
    "        'TMIN': 'TMIN_avg'\n",
    "    }, inplace=True)\n",
    "    return average_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b175f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analysis_data(latitude, longitude, weather_station):\n",
    "    weather_station_data = data_cleaned[data_cleaned['STATION']== weather_station]\n",
    "    \n",
    "    for var in ['AWND', 'PRCP', 'TAVG', 'TMAX', 'TMIN']:\n",
    "        for year in range(1, 6):\n",
    "            year_lag = year*12\n",
    "            weather_station_data[f'{var}_lag_{year}_year'] = weather_station_data[var].shift(year_lag)\n",
    "            \n",
    "    neighbor_data = average_values_for_nearest_stations_exclude(latitude, longitude, weather_station)\n",
    "    merged_data = pd.merge(weather_station_data, neighbor_data, on=['YEAR', 'MONTH'], how='inner')\n",
    "    \n",
    "    for var in ['AWND_avg', 'PRCP_avg', 'TAVG_avg', 'TMAX_avg', 'TMIN_avg']:\n",
    "        for year in range(1, 6):\n",
    "            year_lag = year*12\n",
    "            merged_data[f'{var}_lag_{year}_year'] = merged_data[var].shift(year_lag)\n",
    "    \n",
    "    merged_data_final = merged_data.drop(columns=['AWND', 'TAVG', 'TMAX', 'TMIN', 'AWND_avg', 'PRCP_avg', 'TAVG_avg', 'TMAX_avg', 'TMIN_avg'])\n",
    "    merged_data_final = merged_data_final.dropna()\n",
    "    return merged_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_analysis(latitude, longitude, weather_station):\n",
    "    '''\n",
    "    a specific weather station and its latitude and longitude as input\n",
    "    this part of code is incomplete!!!\n",
    "    '''\n",
    "    \n",
    "    merged_data_final = get_analysis_data(latitude, longitude, weather_station)\n",
    "\n",
    "    # Set the starting and ending years for the time window\n",
    "    years = merged_data_final['YEAR'].unique()\n",
    "    start_year = years[0] + 4 #starting year 2015\n",
    "    end_year = 2022\n",
    "\n",
    "    # Loop through each time window\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # Define the training and testing sets\n",
    "        train_df = merged_data_final[merged_data_final['YEAR'].between(year - 4, year)]\n",
    "        test_df = merged_data_final[merged_data_final['YEAR'] == year + 1]\n",
    "\n",
    "        # Remove rows with missing values\n",
    "        train_df = train_df.dropna()\n",
    "        test_df = test_df.dropna()\n",
    "        \n",
    "###following is the code for model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e81a5",
   "metadata": {},
   "source": [
    "### The way that I split the train set data is that \n",
    "The training set (train_df) contains data from the first 4 years (including the current year) of the current cycle year. This means that if the current cycle year is 2019, then the training set will include data from 2015 to 2019 (both 2015 and 2019).\n",
    "\n",
    "The test set (test_df), on the other hand, contains data from the year immediately following the current loop year. Continuing with the example above, if the current loop year is 2019, then the test set will contain data from 2020."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
